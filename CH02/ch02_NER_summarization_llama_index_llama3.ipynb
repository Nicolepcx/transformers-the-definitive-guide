{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63d53f142e7e4fe3b39a3278ba899999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d33d53e45e40459c753aa2b2240feb",
              "IPY_MODEL_4617309069f14f0694e63e94b9663a84",
              "IPY_MODEL_ba45e01165e74b20b315b321dc57a220"
            ],
            "layout": "IPY_MODEL_800b6924f2c04862b3f532a42d7b062b"
          }
        },
        "a4d33d53e45e40459c753aa2b2240feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39203e84180f4497a7e7acf5ede4289f",
            "placeholder": "​",
            "style": "IPY_MODEL_b2f5209641f3424ab73a0994809fd6c9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4617309069f14f0694e63e94b9663a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80804b88f86c41dc85a7a64a1acd8160",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5d966ca56544cdfa8e302af109e843f",
            "value": 4
          }
        },
        "ba45e01165e74b20b315b321dc57a220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0613574cc64c6aad070c7272861ce9",
            "placeholder": "​",
            "style": "IPY_MODEL_ac98b00c607d412abc7c10e2ad8aab72",
            "value": " 4/4 [00:11&lt;00:00,  2.47s/it]"
          }
        },
        "800b6924f2c04862b3f532a42d7b062b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39203e84180f4497a7e7acf5ede4289f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f5209641f3424ab73a0994809fd6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80804b88f86c41dc85a7a64a1acd8160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d966ca56544cdfa8e302af109e843f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca0613574cc64c6aad070c7272861ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac98b00c607d412abc7c10e2ad8aab72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Open notebook in:\n",
        "| Colab                                 |  Gradient                                                                                                                                         |\n",
        "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/https://github.com/Nicolepcx/transformers-the-definitive-guide/blob/main/CH02/ch02_llama_index_llama3.ipynb)                                              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com//github.com/Nicolepcx/transformers-the-definitive-guide/blob/main/CH02/ch02_llama_index_llama3.ipynb)|             "
      ],
      "metadata": {
        "id": "Gyg1oxapa9iL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About this notebook\n",
        "\n",
        "\n",
        "In this notebook you perform:\n",
        "- Named Entity Recognition\n",
        "- Text Summarization\n",
        "\n",
        "# About this notebook\n",
        "\n",
        "\n",
        "In this notebook you download a file from a publicly accessible file from GoogleDrive and process it with LlamaIndex. You will load the Llama 3 model with [quantization](https://huggingface.co/docs/bitsandbytes/main/en/index) to leverage an optimized, less resource-hungry version of the model for these tasks.\n"
      ],
      "metadata": {
        "id": "tbX2Jhn-bZlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "VWNgh0JCrl6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install llama-index-llms-huggingface==0.1.5 \\\n",
        "                llama-index-embeddings-huggingface==0.2.0 \\\n",
        "                loralib==0.1.2 \\\n",
        "                sentencepiece==0.1.99 \\\n",
        "                bitsandbytes==0.43.0 \\\n",
        "                accelerate==0.28.0 \\\n",
        "                llama-index==0.10.33"
      ],
      "metadata": {
        "id": "8MrceMkNKtJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5841e768-4d62-49fb-a33b-a83798e57c30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "YmmHZYgUN8vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flash-attn --no-build-isolation -q"
      ],
      "metadata": {
        "id": "-ZIV1LkYK-2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import torch\n",
        "import transformers\n",
        "from textwrap import TextWrapper\n",
        "\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "\n",
        "from transformers import (AutoModelForCausalLM,\n",
        "                          AutoTokenizer,\n",
        "                          PreTrainedTokenizer,\n",
        "                          PreTrainedModel,\n",
        "                          BitsAndBytesConfig,\n",
        "                          pipeline\n",
        "                        )\n",
        "\n",
        "from llama_index.core import (SummaryIndex,\n",
        "                              VectorStoreIndex,\n",
        "                              SimpleDirectoryReader,\n",
        "                              StorageContext,\n",
        "                              load_index_from_storage,\n",
        "                              Settings,\n",
        "                              PromptTemplate\n",
        ")\n",
        "\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.llms import ChatMessage"
      ],
      "metadata": {
        "id": "VoAyABfPLCnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_wrapper(print):\n",
        "    \"\"\"Adapted from: https://stackoverflow.com/questions/27621655/how-to-overload-print-function-to-expand-its-functionality/27621927\"\"\"\n",
        "\n",
        "    def function_wrapper(text):\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "        wrapper = TextWrapper()\n",
        "        return print(\"\\n\".join([wrapper.fill(line) for line in text.split(\"\\n\")]))\n",
        "\n",
        "    return function_wrapper\n",
        "\n",
        "print = print_wrapper(print)"
      ],
      "metadata": {
        "id": "FBBT2u_8EGE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, destination_folder):\n",
        "    \"\"\"\n",
        "    Download a file from a URL to the specified destination folder.\n",
        "    Attempts to use the original filename from the Content-Disposition header.\n",
        "    \"\"\"\n",
        "    # Ensure the destination folder exists\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    # Get the file content from the URL\n",
        "    response = requests.get(url, allow_redirects=True)\n",
        "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "    # Try to fetch the filename from the content disposition header\n",
        "    content_disposition = response.headers.get('content-disposition')\n",
        "    if content_disposition:\n",
        "        # Extract filename from content_disposition\n",
        "        filename = content_disposition.split('filename=')[1].strip('\"')\n",
        "    else:\n",
        "        # If no filename is found in the headers, default to a filename\n",
        "        filename = \"default_filename.txt\"\n",
        "\n",
        "    # Create the full path for the local file\n",
        "    local_file_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "    # Write the file content in binary mode to the local file\n",
        "    with open(local_file_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    return local_file_path"
      ],
      "metadata": {
        "id": "iZcQyQZ4Jt-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face access token\n",
        "hf_token = \"your_access_token\"\n",
        "\n",
        "# HfFolder to save the token for subsequent API calls\n",
        "HfFolder.save_token(hf_token)"
      ],
      "metadata": {
        "id": "LKg6hemOLUMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Infos about chat template for llama 3: https://github.com/meta-llama/llama-recipes\n",
        "system_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "                    You are a helpful, respectful, and honest assistant.\n",
        "                    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "                \"\"\"\n",
        "\n",
        "# This will wrap the default prompts that are internal to llama-index\n",
        "query_wrapper_prompt = PromptTemplate(\"{query_str}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")"
      ],
      "metadata": {
        "id": "Dt2KBBrH86Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=hf_token)\n",
        "\n",
        "stopping_ids = [\n",
        "    tokenizer.eos_token_id,\n",
        "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\"),\n",
        "]\n",
        "\n",
        "# BitsAndBytes configuration\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    load_in_8bit=False, # You can optionally load it in 8bit\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_quant_type=\"fp4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    model_name=model_id,\n",
        "    max_new_tokens=512,\n",
        "    model_kwargs={\n",
        "        \"token\": hf_token,\n",
        "        \"quantization_config\": bnb_config\n",
        "    },\n",
        "    generate_kwargs={\n",
        "        \"do_sample\": True,\n",
        "        \"temperature\": 0.6,\n",
        "        \"top_p\": 0.9,\n",
        "    },\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=model_id,\n",
        "    tokenizer_kwargs={\"token\": hf_token},\n",
        "    stopping_ids=stopping_ids,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "63d53f142e7e4fe3b39a3278ba899999",
            "a4d33d53e45e40459c753aa2b2240feb",
            "4617309069f14f0694e63e94b9663a84",
            "ba45e01165e74b20b315b321dc57a220",
            "800b6924f2c04862b3f532a42d7b062b",
            "39203e84180f4497a7e7acf5ede4289f",
            "b2f5209641f3424ab73a0994809fd6c9",
            "80804b88f86c41dc85a7a64a1acd8160",
            "b5d966ca56544cdfa8e302af109e843f",
            "ca0613574cc64c6aad070c7272861ce9",
            "ac98b00c607d412abc7c10e2ad8aab72"
          ]
        },
        "id": "E1K4MkvtLSkA",
        "outputId": "59354dde-e381-4cff-b3ba-c062b5533f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63d53f142e7e4fe3b39a3278ba899999"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = llm"
      ],
      "metadata": {
        "id": "35VD8T0sDiOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"\n",
        "Tim Cook is CEO of Apple. Apple is an American multinational\n",
        "corporation and technology company headquartered in Cupertino,\n",
        "California, in Silicon Valley.\n",
        "\"\"\"\n",
        "\n",
        "text = f\"Find all entities in the following \\n\\n {input_text}, and return only the entities.\"\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTvFUuDlFsbX",
        "outputId": "3c6d3f96-d591-4c05-ab6d-c31753f462bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Find all entities in the following\n",
            "\n",
            "\n",
            "Tim Cook is CEO of Apple. Apple is an American multinational\n",
            "corporation and technology company headquartered in Cupertino,\n",
            "California, in Silicon Valley.\n",
            ", and return only the entities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    ChatMessage(role=\"system\", content=\"You are and entities expert and can find all entities in a text.\"),\n",
        "    ChatMessage(role=\"user\", content=text),\n",
        "]\n",
        "response = llm.chat(messages)"
      ],
      "metadata": {
        "id": "BMvEuukeMfm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da03890e-0a7d-4341-ebec-351d9ad40d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjQw40FjF1ts",
        "outputId": "7ab2feb4-e6c0-4ced-b1fc-ff829e366df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: assistant\n",
            "\n",
            "Here are the entities found in the text:\n",
            "\n",
            "* Tim Cook (Person)\n",
            "* Apple (Organization)\n",
            "* California (Location)\n",
            "* Cupertino (Location)\n",
            "* Silicon Valley (Location)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of publicly shared Google Drive PDF file URLs\n",
        "urls = [\n",
        "    \"https://drive.google.com/uc?export=download&id=1EhXzZd2YHs0qzMwxF3EzaljMfVgLDYEK\",\n",
        "]\n",
        "\n",
        "# Destination folder\n",
        "destination_folder = \"data\"\n",
        "\n",
        "# Download each file\n",
        "for url in urls:\n",
        "    print(f\"Downloading from {url}...\")\n",
        "    file_path = download_file(url, destination_folder)\n",
        "    print(f\"Saved to {file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDX0HBXC-k6M",
        "outputId": "442cc5e6-b895-48c9-9bcf-87d5c7387e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://drive.google.com/uc?export=download&id=1EhXzZ\n",
            "d2YHs0qzMwxF3EzaljMfVgLDYEK...\n",
            "Saved to data/medical_record.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iYeofUlS6_D"
      },
      "source": [
        "# Index Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader('./data').load_data()\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6lJBkB4-_aG",
        "outputId": "74eb12eb-b251-4b94-abe7-423555c300c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding model - You need to add this\n",
        "# otherwise it will ask yu for OpenAI credentials\n",
        "embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"hkunlp/instructor-large\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZHfr_g7BR5N",
        "outputId": "c8ae985c-1b2d-4b90-8765-181a88fe6683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZl7SgPCVrg5"
      },
      "outputs": [],
      "source": [
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.num_output = 256\n",
        "Settings.context_window = 4096\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz173lnJS8cZ"
      },
      "outputs": [],
      "source": [
        "vector_index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    vector_index.as_query_engine(\n",
        "        llm=llm,\n",
        "    ).query(\"Provide a short summary of the patient record of Pamela Rogers\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Vb-QIW_MFO",
        "outputId": "0a315190-84f5-4856-926d-0ff3b24a5d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Here is a short summary of the patient record of Pamela Rogers:\n",
            "\n",
            "Pamela Rogers, a 56-year-old woman, was admitted to the emergency\n",
            "department with a chief complaint of chest pains. She reported\n",
            "experiencing dull and aching chest pain, which radiates to her neck,\n",
            "accompanied by shortness of breath. The pain occurs approximately once\n",
            "a week, usually after working in her garden or engaging in physical\n",
            "activity. The patient has a history of hypertension, diagnosed 3 years\n",
            "ago, but has never been told she has heart problems. She does not\n",
            "smoke or have diabetes. Her physical examination revealed normal vital\n",
            "signs, no abnormal findings on her skin, HEENT, and neurological\n",
            "examination, and a grade 2/6 systolic decrescendo murmur in the second\n",
            "right intercostal space.\n"
          ]
        }
      ]
    }
  ]
}