{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Open notebook in:\n",
        "| Colab                                 |  Gradient                                                                                                                                         |\n",
        "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Nicolepcx/transformers-the-definitive-guide/blob/master/CH03/ch03_STORM.ipynb)                                             | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com//github.com/Nicolepcx/transformers-the-definitive-guide/blob/main/CH03/ch03_STORM.ipynb)|             "
      ],
      "metadata": {
        "id": "UnrBeLs8Rz-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#About this notebook\n",
        "\n",
        "This notebook is implements and evaluates the STORM model, which stands for [Stochastic Transformer-based wORld Model](https://openreview.net/pdf?id=WxnrX42rnS). The STORM model is a reinforcement learning architecture that efficiently combines the sequence modeling power of transformers with the stochastic nature of variational autoencoders to enhance agent performance in complex environments.\n",
        "\n",
        "Key Features of This Notebook:\n",
        "- Repository Cloning and Setup: The notebook starts by cloning the official STORM repository, installing necessary dependencies, and setting up the environment for running the model.\n",
        "- Model Checkpoint Management: It includes downloading and decompressing model checkpoints that are essential for evaluating the STORM model's performance.\n",
        "- Evaluation Script Creation: The notebook creates a custom Python evaluation script that sets up the environment, loads the trained world model and agent, and evaluates the agent's performance by generating a video of its actions within the environment.\n",
        "- Execution and Output: The notebook concludes by running the evaluation script and saving the output video, which visualizes the agent's behavior and performance within the selected environment.\n",
        "\n",
        "Context of STORM:\n",
        "The STORM model is an advanced approach in model-based reinforcement learning, where a parameterized simulation model of the environment is constructed through self-supervised learning. This model helps the agent improve its policy without constantly relying on real environment samples, making training more efficient.\n",
        "\n",
        "Performance:\n",
        "STORM sets a new benchmark with a mean human performance of 126.7% on the Atari 100k benchmark, and its efficient training process makes it highly practical for real-world applications.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3igahluq2HOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "u6ze5EIvpXrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/Nicolepcx/STORM.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdEkHS-dOcJ0",
        "outputId": "4aca2ba5-716a-4798-ed19-4ae73a7367c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'STORM'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 66 (delta 23), reused 16 (delta 16), pack-reused 26\u001b[K\n",
            "Receiving objects: 100% (66/66), 516.24 KiB | 1.82 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Change directory to the cloned repo\n",
        "%cd STORM\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uckf9cWeOgJa",
        "outputId": "5529de4e-e692-4251-c645-59752842edda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STORM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueOPsu4_OiKc",
        "outputId": "7562f4f6-3e27-4944-e3d3-e3919c9a80d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agents.py      env_wrapper.py  readme.md         \u001b[0m\u001b[01;34msub_models\u001b[0m/     train.sh\n",
            "\u001b[01;34mconfig_files\u001b[0m/  eval.py         replay_buffer.py  TensorBoard.sh  utils.py\n",
            "D_TRAJ.7z      eval.sh         requirements.txt  train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt -qqq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H7dryu9Ozi4",
        "outputId": "60648c74-9294-4d6a-dc1a-95c417b983a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.18.0+cu121)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.1.8)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.6.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.15.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.0.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.4.6)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.66.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.8.0.76)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 3)) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->-r requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 5)) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 7)) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 7)) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]->-r requirements.txt (line 12)) (2.2.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]->-r requirements.txt (line 12)) (0.0.4)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]->-r requirements.txt (line 12)) (0.4.2)\n",
            "Requirement already satisfied: shimmy[atari]<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]->-r requirements.txt (line 12)) (0.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]->-r requirements.txt (line 12)) (8.1.7)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]->-r requirements.txt (line 12)) (0.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 6)) (2024.6.2)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]->-r requirements.txt (line 12)) (6.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the checkpoints from Google Drive\n",
        "\n",
        "Here you download the model checkpoints from my training of STORM."
      ],
      "metadata": {
        "id": "5GhKcpUxpdw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1qbQ5b6cfuQHf-nanfXAKcRxlpZJ1zU7R --output model_checkpoints.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaRYvbF8Q7GJ",
        "outputId": "d540e80b-d134-4fbe-8f84-81c98718d81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qbQ5b6cfuQHf-nanfXAKcRxlpZJ1zU7R\n",
            "From (redirected): https://drive.google.com/uc?id=1qbQ5b6cfuQHf-nanfXAKcRxlpZJ1zU7R&confirm=t&uuid=94bd83d9-edc3-4020-a364-c1eb884b7aec\n",
            "To: /content/STORM/model_checkpoints.tar.gz\n",
            "100% 3.03G/3.03G [01:35<00:00, 31.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decompress the checkpoints"
      ],
      "metadata": {
        "id": "CQH2UekbptZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!tar -xzvf model_checkpoints.tar.gz -C .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB2vpCmTQR_p",
        "outputId": "7a3f2eea-07f1-4086-a27b-6dad16de7b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ckpt/\n",
            "ckpt/.ipynb_checkpoints/\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_100000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_100000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_97500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_97500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_95000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_95000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_92500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_92500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_90000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_90000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_87500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_87500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_85000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_85000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_82500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_82500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_80000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_80000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_77500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_77500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_75000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_75000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_72500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_72500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_70000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_70000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_67500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_67500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_65000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_65000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_62500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_62500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_60000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_60000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_57500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_57500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_55000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_55000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_52500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_52500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_50000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_50000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_47500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_47500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_45000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_45000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_42500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_42500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_40000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_40000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_37500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_37500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_35000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_35000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_32500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_32500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_30000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_30000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_27500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_27500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_25000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_25000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_22500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_22500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_20000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_20000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_17500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_17500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_15000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_15000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_12500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_12500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_10000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_10000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_7500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_7500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_5000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_5000.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_2500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_2500.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/agent_0.pth\n",
            "ckpt/RoadRunner-life_done-wm_2L512D8H-100k-seed1/world_model_0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Evaluation Script"
      ],
      "metadata": {
        "id": "zHKOTBFNpxFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p eval_result\n",
        "\n",
        "# Make the eval.sh script executable\n",
        "!chmod +x eval.sh\n",
        "\n",
        "# Run the eval.sh script\n",
        "!./eval.sh\n",
        "\n",
        "# Create the evaluation script\n",
        "eval_script = \"\"\"\n",
        "import gymnasium\n",
        "import argparse\n",
        "from utils import load_config\n",
        "from sub_models.world_models import WorldModel\n",
        "import agents\n",
        "import torch\n",
        "import imageio\n",
        "import env_wrapper  # Ensure this is imported\n",
        "\n",
        "def build_single_env(env_name, image_size, seed):\n",
        "    env = gymnasium.make(env_name, full_action_space=False, render_mode=\"rgb_array\", frameskip=1)\n",
        "    env = env_wrapper.SeedEnvWrapper(env, seed=seed)\n",
        "    env = env_wrapper.MaxLast2FrameSkipWrapper(env, skip=4)\n",
        "    env = gymnasium.wrappers.ResizeObservation(env, shape=image_size)\n",
        "    env = env_wrapper.LifeLossInfo(env)\n",
        "    return env\n",
        "\n",
        "def evaluate(env, world_model, agent, video_path):\n",
        "    obs, _ = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    frames = []\n",
        "\n",
        "    while not done:\n",
        "        frames.append(env.render())\n",
        "        action = agent.select_action(world_model.encode_obs(obs))\n",
        "        obs, reward, done, _, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "    env.close()\n",
        "    imageio.mimsave(video_path, frames, fps=30)\n",
        "    return total_reward\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"-n\", type=str, required=True)\n",
        "    parser.add_argument(\"-config_path\", type=str, required=True)\n",
        "    parser.add_argument(\"-env_name\", type=str, required=True)\n",
        "    parser.add_argument(\"-checkpoint_path\", type=str, required=True)\n",
        "    parser.add_argument(\"-video_path\", type=str, required=True, help=\"Path to save the output video\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    conf = load_config(args.config_path)\n",
        "    env = build_single_env(args.env_name, conf.BasicSettings.ImageSize, seed=0)\n",
        "    action_dim = env.action_space.n\n",
        "\n",
        "    world_model = WorldModel(\n",
        "        in_channels=conf.Models.WorldModel.InChannels,\n",
        "        action_dim=action_dim,\n",
        "        transformer_max_length=conf.Models.WorldModel.TransformerMaxLength,\n",
        "        transformer_hidden_dim=conf.Models.WorldModel.TransformerHiddenDim,\n",
        "        transformer_num_layers=conf.Models.WorldModel.TransformerNumLayers,\n",
        "        transformer_num_heads=conf.Models.WorldModel.TransformerNumHeads\n",
        "    ).cuda()\n",
        "    agent = agents.ActorCriticAgent(\n",
        "        feat_dim=32*32+conf.Models.WorldModel.TransformerHiddenDim,\n",
        "        num_layers=conf.Models.Agent.NumLayers,\n",
        "        hidden_dim=conf.Models.Agent.HiddenDim,\n",
        "        action_dim=action_dim,\n",
        "        gamma=conf.Models.Agent.Gamma,\n",
        "        lambd=conf.Models.Agent.Lambda,\n",
        "        entropy_coef=conf.Models.Agent.EntropyCoef,\n",
        "    ).cuda()\n",
        "\n",
        "    world_model.load_state_dict(torch.load(f\"{args.checkpoint_path}/world_model.pth\"))\n",
        "    agent.load_state_dict(torch.load(f\"{args.checkpoint_path}/agent.pth\"))\n",
        "\n",
        "    total_reward = evaluate(env, world_model, agent, args.video_path)\n",
        "    print(f\"Total reward: {total_reward}\")\n",
        "   \"\"\"\n",
        "\n",
        "with open(\"eval.py\", \"w\") as file:\n",
        "    file.write(eval_script)\n",
        "\n",
        "# Step 10: Run the evaluation script and save the video\n",
        "!python eval.py -n STORM_eval -config_path config_files/STORM.yaml -env_name ALE/RoadRunner-v5 -checkpoint_path ckpt/MsPacman-life_done-wm_2L512D8H-100k-seed1 -video_path output_video.mp4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noilcURzWnym",
        "outputId": "1996047d-7c79-440a-93e0-e368ac291042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mNamespace(config_path='config_files/STORM.yaml', env_name='ALE/RoadRunner-v5', run_name='RoadRunner-life_done-wm_2L512D8H-100k-seed1')\u001b[0m\n",
            "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
            "[Powered by Stella]\n",
            "[100000]\n",
            "  0% 0/1 [00:00<?, ?it/s]Current env: \u001b[33mALE/RoadRunner-v5\u001b[0m\n",
            "Mean reward: \u001b[33m16960.0\u001b[0m\n",
            "100% 1/1 [00:49<00:00, 49.96s/it]\n",
            "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
            "[Powered by Stella]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/STORM/eval.py\", line 66, in <module>\n",
            "    world_model.load_state_dict(torch.load(f\"{args.checkpoint_path}/world_model.pth\"))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 997, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 444, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 425, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'ckpt/MsPacman-life_done-wm_2L512D8H-100k-seed1/world_model.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7Zyh1r0hYp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}